\documentclass[12pt, letterpaper]{article}


\usepackage[utf8]{inputenc}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{blindtext}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{conjecture}[theorem]{Conjecture}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]



\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\newcommand{\F}{\mathbb{F}}
\newcommand{\M}{M_{2\times 2}(\mathbb{F}_p)}

\title{Recurrence Relations in Non-Commutative Finite Rings}
\author{Oren Maximov}

\begin{document}
\maketitle
\section{Introduction}


A recurrence relation in a ring $R$ is an equation that defines a sequence by giving the next term as a function of one or some of the previous terms. For example, a recurrence relation in $R$ given by the previous two terms looks like \[A_n = f(A_{n-1},A_{n-2}),\] where each $A_i \in R$.


\begin{definition}
The \textbf{Lie bracket recurrence relation} is defined as \[A_n = A_{n-1}A_{n-2}-A_{n-2}A_{n-1}.\] We call the resulting sequence the \textbf{Lie sequence}. We say $A,B \in \M$ \textbf{generates} the Lie sequence, and that $A$ and $B$ are the \textbf{initial conditions} if the first two terms of the sequence are $A$ and $B$,in that order.
\end{definition}
\par Observe that in a commutative ring, this relation is uninteresting, so we consider the relation over a non-commutative ring, $\M$. Since this is a finite field, we would expect some kind of repitition to arise. Thus, we need some additional terminology to describe what's going on.
\begin{definition}
Let $s = (A_0,A_1,A_2\dots)$ be the Lie sequence generated by $A_0,A_1$. Then $s$ has \textbf{period $k$} if $(\exists N \in \mathbb{N})(\forall n\geq N) A_{n+k} = A_n$. We call the sequence of  matrices $A_N \dots A_{N+k-1}$ the \textbf{periodic portion}. We call the sequences of matrices $A_0 \dots A_{N-1}$ the \textbf{pre-periodic portion}, and say the $s$ has \textbf{pre-period} N.
\end{definition}

\par  Thus, we used sagemath to iterate over various initial conditions in $M_{2x2}(\mathbb{F}_p)$ and recorded of the period and pre-period of the sequence. From this data, we began to hone in on some important details, such as eigenvalues, and the field from which the entries of the matrix come, about the initial conditions and how they related to the period of the sequence.





\section{Lemmas}
The following are lemmas that we have found in research, or were already known and that we utilized. (I will specify if the latter is the case.)

\begin{lemma}
Let $s = (A_0,A_1,A_2\dots)$ be a Lie sequence generated by $A_0,A_1$, where each $A_i \in R$, for some ring $R$. If $(\exists i \in \mathbb{N}) A_i = 0$, then:
\begin{enumerate}
\item Every successive element is 0.
\item The sequence has period 1.
\end{enumerate}
\end{lemma}

\begin{proof}
Let $s$ be the sequence as in the hypothesis. Let $A_k=0$.

\begin{align*}
A_{k+1} &= A_kA_{k-1}-A_{k-1}A_k \\
&= 0A_{k-1} - A_{k-1}0 \\
&= 0.
\end{align*}
This calculation can be repeated for any $n>k$, thus proving part 1 of the lemma. Now, write $s = (A_0,A_1,\dots A_{k-1}, 0,0,0,\dots)$. We prove $s$ has period 1. For $N=k$, we can see that for all $n\geq N, A_n=0=A_{n+1}$. Thus, $s$ has period 1.


\end{proof}

\begin{lemma}
Let $A_0, A_1,X\in\M.$ Let $A_0' = XA_0X^{-1}, A_1' = XA_1X^{-1}.$ The sequence generated by $A_0,A_1$ and the sequence generated by $A_0',A_1'$ will have the same period and pre-period.
\end{lemma}
\begin{proof}
Let $A_i$ denote the $i$th term of the sequence. Let $A_0, A_1$ be the first two terms of the periodic portion of the series-- that is, ignore the pre-periodic portion of the sequence, and let $A_0' = XA_0X^{-1}, A_1' = XA_1X^{-1}$ We prove that ($\forall n\in \mathbb{N}), A_n' = XA_nX^{-1}$. We proceed by induction on $n$.
\\Base case: $n$ = 2.
\begin{align*}
A_2' &=  A_1'A_0'-A_0'A_1' \\
&= XA_1X^{-1}XA_0X^{-1}-XA_0X^{-1}XA_1X^{-1} \\
&=XA_1A_0X^{-1}- XA_0A_1X^{-1} \\
&= X(A_1A_0-A_0A_1)X^{-1} \\
&= XA_2X^{-1}
\end{align*}
\\Inductive hypothesis: Suppose the lemma holds for all $n$ up to some $k \geq 2$.
\\Inductive step: Let $n = k+1$.
\begin{align*}
A_{k+1}' &= A_k'A_{k-1}'-A_{k-1}'A_k' \\
&= XA_{k+1}X^{-1} \text{, by the same reasoning as in the base case.} \\
\end{align*}
Thus, ($\forall k\in \mathbb{N}), A_k' = XA_kX^{-1}$. This tells us that if, for some $j, A_k = A_{k+j}$ and $A_{k+1} = A_{k+j+1},$ then $A_k' = A_{k+j}'$ and $A_{k+1}' = A_{k+j+1}'$. This means they have the same period length.
\end{proof}

\begin{lemma}
If $A,B \in \M$ share a common eigenvector $\mathbf{v} \in \mathbb{F}_p^2$, we may assume that the common eigenvector is $\mathbf{u} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$ and preserve the behavior of the sequence.
\end{lemma}
\begin{proof}
Let $\mathbf{v} \in \mathbb{F}_p^2$ be any non-zero vector. Then, there exists a nonsingular matrix $X \in \M$ such that $X\mathbf{v} = \mathbf{u}$. Then, we can write $X^{-1}\mathbf{u} = \mathbf{v}$. Let $A \in \M$ have eigenvector $\mathbf{v}$ with eigenvalue $\lambda$. $A' = XAX^{-1}$ has the same eigenvalue $\lambda$ with eigenvector $\mathbf{u}$, since
\begin{align*}
A'\mathbf{u} &= XAX^{-1}\mathbf{u} \\
&= XA\mathbf{v} \\
&= X\lambda\mathbf{v} = \lambda X\mathbf{v} = \lambda\mathbf{u}
\end{align*}
By the previous lemma, we know that conjugating the initial conditions by the same matrix gives the same behavior, so we lose no generality by assuming the common eigenvector is $\mathbf{u}$.
\end{proof}

\begin{lemma}
Matrices in the periodic portion of the sequence have trace 0. Note: this is not an original result-- it is well known that for $A,B \in \M$, $BA-AB$ has trace 0.
\end{lemma}

\begin{proof}
Let $A,B \in \M$ be any matrices. Let $C=AB, D=BA$, as in the lie bracket relation. Write each entry of $C$ and $D$ as $c_{ij}$ and $d_{ij}$, respectively. Consider $c_{kl}$. We can find it by writing \[c_{kl} = \sum\limits_{m=1}^{n} a_{km}b_{ml}.\] Likewise, we can write \[d_{kl} = \sum\limits_{m=1}^{n} b_{km}a_{ml}.\] Now, tr$(BA-AB)$ can be written as
\begin{align*}
tr(D-C) &= \sum\limits_{p=1}^{2} d_{pp}-c_{pp} \\
&= \sum\limits_{p=1}^{2} \sum\limits_{m=1}^{2}b_{pm}a_{mp}-a_{pm}b_{mp} \\
&= 0.
\end{align*}
Thus, any matrix computed in the sequence must have trace 0. Also, note that we can prove that this holds for any $n$x$n$ matrix, by replacing any instance of 2 with $n$.
\end{proof}

\begin{lemma}
There is no sequence with period 2.
\end{lemma}

\begin{proof}
Let $A,B \in \M$ be the two matrices in the period 2 sequence. That is, after some pre-periodic portion of matrices, the sequence looks like $A,B,A,B,A,\dots$. Then, by the Lie bracket relation,
\begin{align*}
A &= BA-AB \\
B &= AB-BA. \\
\end{align*}
This gives us $A=-B$. Substituting $-B$ in for $A$ in the first equation, we get $A=0$. Then, $B=0$. But this is a contradiction, since we assumed this sequence has period 2.
\end{proof}


\begin{lemma}
No period 3 sequences can have a matrix of the form
$\begin{pmatrix}
0 & 0 \\
a & 0
\end{pmatrix}$ where $a \in \F_p$
\end{lemma}


\begin{proof}
Let $A = \begin{pmatrix}
0 & 0\\
a & 0
\end{pmatrix}, B = \begin{pmatrix}
b_0 & b_1 \\
b_2 & -b_0
\end{pmatrix}$, and $\begin{pmatrix}
c_0 & c_1 \\
c_2 & -c_0
\end{pmatrix}$. By applying the lie bracket recurrence relation $A = CB-BC, B = CA - AC, C = BA - AB$, we get the following matrices:
\begin{align*}
\begin{pmatrix}
0 & 0\\
a & 0
\end{pmatrix} & = \begin{pmatrix}
b_2c_1 - b_1c2 & 2b_1c_0-2b_0c_1 \\
-2b_2c_0+2b_0c_2 & -b_2c_1 + b_1c_2
\end{pmatrix}\\
\begin{pmatrix}
b_0 & b_1 \\
b_2 & -b_0
\end{pmatrix} & = \begin{pmatrix}
-a_0c_1 & 0\\
2a_0c_0 & a_0c_1
\end{pmatrix} \\
\begin{pmatrix}
c_0 & c_1 \\
c_2 & -c_0
\end{pmatrix} & = \begin{pmatrix}
a_0b_1 & 0 \\
-2a_0b_0 & -a_0b_1
\end{pmatrix}
\end{align*}
By substituting in that $b_1 = c_1 = 0$, we can get one of the matrices to become the zero matrix, and thus reach a contradiction.
\end{proof}






\section{Results and conjectures}
Upon noticing that sequences of period 3 were cropping up, we honed in on that as a topic of study. Moving forward, let our lie bracket sequences be $A,B,C,A,B,C\dots$, where
\begin{align*}
A &= \begin{pmatrix}
a_0 & a_1 \\
a_2 & -a_0
\end{pmatrix}\\
B &= \begin{pmatrix} b_0 & b_1 \\ b_2 &  -b_0 \end{pmatrix}\\
C &=\begin{pmatrix} c_0 & c_1 \\ c_2 & -c_0 \end{pmatrix}
\end{align*}
\subsection{The minimum polynomial}Each of these matrices, $A,B,C$ have minimum polynomial $m = X^2+\alpha X + \delta$, where $\alpha$ is the trace of the matrix and $\delta$ is the determinant. We know that the trace must be 0, so we can say $m=X^2+\delta$.
There are 3 cases to consider:
\begin{enumerate}
\item $\delta = 0$. Then, $m=X^2$, so the matrix A has eigenvalue 0, has eigenvector $\begin{pmatrix} 0 \\ 1\end{pmatrix}$ (by lemma 2.2) and is conjugate to $A'=
\begin{pmatrix}
a & 0 \\
c & -a
\end{pmatrix}.$ Then, we get the following equation:
\begin{equation}
\begin{pmatrix}
a & 0 \\
c & -a
\end{pmatrix}
\begin{pmatrix}
0\\
1
\end{pmatrix}
= 0
\begin{pmatrix}
0\\
1
\end{pmatrix}
=
\begin{pmatrix}
0 \\
0
\end{pmatrix}
\end{equation}. Thus $a$ = 0. So $A' =
\begin{pmatrix}
0 & 0 \\
c & 0
\end{pmatrix}$. By Lemma 2.5, a matrix of this form cannot exist in the period 3 case. Thus, we cannot have $\delta = 0$.

\item $\delta = -\lambda^2$, for some $\lambda$.
\item $-\delta$ is not a square modulo $p$.
\end{enumerate}

We treat cases 2 and 3 together. We begin by conjugating $A, B, C$ so that $A$ has a simpler form, giving us
\begin{align*}
A &= \begin{pmatrix} -a & 0 \\ c & a \end{pmatrix}\\
B &= \begin{pmatrix} e & f \\ g & -e \end{pmatrix}\\
C &= \begin{pmatrix} w & x \\ y & -w \end{pmatrix}.
\end{align*}
Applying $A=CB-BC, B = AC-CA, C = BA-AB$, we get
\begin{align*}
A &= \begin{pmatrix} gx-fy & 2fw-2ex \\ -2gw+2ey & -gx+fy \end{pmatrix}\\
B &= \begin{pmatrix}
-cx & -2ax \\ 2cw+2ay & cx
\end{pmatrix}\\
C &= \begin{pmatrix}
cf & 2af \\ -2ce-2ag & -cf
\end{pmatrix}
\end{align*}
After some algebraic manipulation, we get $x=-4a^2x$. If $x=0$, the matrices zero out giving us a contradiction so we must assume that $a$ is a solution to $4a^2+1=0$. This tells us that the matrix has eigenvalues $\pm\frac{i}{2}$, where $i^2=-1$. Such an $i$ can only exist in $\F_p$ for $p\equiv 1\pmod 4$. But we know from experimentation on sage that such sequences exist even when $p \equiv 3\pmod 4.$

\subsection{General form of period 3 matrices} By using sage and conjugating the matrix $A$ to $\begin{pmatrix} a_0 & 0 \\ a_2 & -a_0 \end{pmatrix}$, and writing $B$ and $C$ as in the beginning of the section, we were able to find the general form of $A$, $B$, and $C$.
\begin{align*}
A &= \begin{pmatrix}
\frac{-i}{2} & 0 \\
a & \frac{i}{2}
\end{pmatrix}\\
B &= \begin{pmatrix}
-abi & b\\
\frac{4a^2b^2-1}{4b} & abi
\end{pmatrix}\\
C&=\begin{pmatrix}
ab & bi\\
\frac{4a^2b^2i-1}{4b} & abi
\end{pmatrix}
\end{align*}
Notice that the eigenvalues of $A$ are $\pm\frac{i}{2}$. When $p\equiv 3\pmod 4$, the eigenvalues are not in $\F_p$, and thus this form of matrices is the best we can do. To get a sequence of period 3 in such a field, we must conjugate $A$ by some matrix $X \in GL_2(\mathbb{F}_{p^2})$. Such a conjugation is possible, as evidenced by the existence of period 3 sequences in those fields from the sage experimentation, but more inquiry into what sorts of matrices can do this is necessary.
\\When $p \equiv 1 \pmod 4$, we can write them as follows:
\begin{align*}
A &= \begin{pmatrix} \frac{i}{2} & 0 \\ 0 & \frac{-i}{2}\end{pmatrix} \\
B & = \begin{pmatrix} 0 & b \\ \frac{-1}{4b} & 0 \end{pmatrix} \\
C &= \begin{pmatrix} 0 & ib \\ \frac{i}{4b} & 0 \end{pmatrix}
\end{align*}
for some parameter $b$ and $i^2 = -1$. Here, we invoke a proposition from Dummit and Foote's \textit{Abstract Algebra}, which states that if a matrix has entries from $\F_p$ and it contains its eigenvalues, and the eigenvalues are in $\F$, then the matrix is similar to a diagonal matrix with its eigenvalues on the diagonal.



\subsection{Counting the period 3 sequences}
\subsubsection{$p\equiv 1 \pmod 4$} Let $p \equiv 1 \pmod 4$. Let $\overbar{s} = A,B,C,A,B,C...$ be a period 3 sequence. Then, we know that every $\overbar{s}$ is conjugate to \[\overbar{t} =
\begin{pmatrix}
\frac{i}{2} & 0\\
0 & \frac{-i}{2}
\end{pmatrix},
\begin{pmatrix}
0 & \frac{1}{2} \\
\frac{-1}{2} & 0
\end{pmatrix}
\begin{pmatrix}
0 & \frac{i}{2} \\
\frac{-i}{2} & 0
\end{pmatrix}.
\]
So, the number of period 3 sequences can be written as the number of distinct lists that can be obtained by conjugating $\overbar{t}$. The number of ways to conjugate $\overbar{t}$ is given by \[\frac{|(GL_2(\F_p))|}{N},\]
where $N$ is the number of matrices with conjugate $\overbar{t}$ to some sequence $\overbar{t`}$.  Then, using set-builder notation, we can reduce the problem as follows:
\begin{align*}
N &= |\{X \in GL_2(F_p):\text{$X$ conjugates $\overbar{t}$ to itself}\}| \\
&= |\{X:XAX^{-1}=A,XBX^{-1}=B,XCX^{-1}=C\}| \\
&= |\{X:XA=AX \text{ and } XB=BX\}| \\
&= |\text{cent}(A) \cap \text{cent}(B)| \\
&= p-1.
\end{align*}
The cardinality of $\text{cent}(A) \cap\text{cent(B)}$ can be computed algebraically. Now, the number of ways to conjugate $\overbar{t}$ is
\[\frac{|GL_2(\F_p)}{p-1}| = \frac{(p^2-p)(p^2-1)}{p-1} = p(p+1)(p-1).\] Thus, there are $p(p+1)(p-1)$ sequences of period 3 when $p \equiv 1\pmod 4$.
\subsubsection{$p\equiv 3\pmod 4$}Let $p \equiv 3\pmod 4$. Let $\overbar{s} = A,B,C,A,B,C\dots$ be a period 3 sequence. Every $\overbar{s}$ must be conjugate to  \[\overbar{t} = \begin{pmatrix}
\frac{-i}{2} & 0 \\
a & \frac{i}{2}
\end{pmatrix},
\begin{pmatrix}
-abi & b\\
\frac{4a^2b^2-1}{4b} & abi
\end{pmatrix},
\begin{pmatrix}
ab & bi\\
\frac{4a^2b^2i-1}{4b} & abi
\end{pmatrix}\].  Notice that $i \notin \F_p$, given the current value of $p$, so we cannot simplify these matrices any further.

\section{Acknowledgements}I would like to thank Professor Chris Rasmussen for being so accessible and patient, and for guiding me through this project. In addition, I would like to thank Wesleyan university for providing the funding for the work.
\end{document}


